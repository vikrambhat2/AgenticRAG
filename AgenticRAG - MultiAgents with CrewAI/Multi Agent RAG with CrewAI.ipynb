{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agentic RAG for PDF-based Question Answering**\n",
    "\n",
    "## **Introduction**\n",
    "This notebook implements an **Agentic RAG (Retrieval-Augmented Generation) system** for querying PDFs using **CrewAI**. It employs two autonomous agents:  \n",
    "\n",
    "- **PDFRetrievalAgent**: Retrieves the most relevant document excerpts using FAISS and sentence-transformer embeddings.  \n",
    "- **LLMAgent**: Processes retrieved content and generates responses while ensuring answers are strictly grounded in the document.  \n",
    "\n",
    "The system follows a **multi-step workflow** where agents collaborate to ensure accuracy, reducing hallucination risks. This approach is useful for **research papers, legal documents, reports, or any structured knowledge retrieval task**.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Required Libraries**  \n",
    "\n",
    "This section imports the essential libraries for building an **Agentic RAG system** to process PDFs and answer user queries.  \n",
    "\n",
    "### **Libraries Overview:**  \n",
    "- **CrewAI Components (`Agent`, `Task`, `Crew`, `Process`)**  \n",
    "  - Define and manage autonomous agents for retrieval and response generation.  \n",
    "\n",
    "- **LangChain for Document Processing**  \n",
    "  - `PyPDFLoader`: Loads and extracts text from PDFs.  \n",
    "  - `RecursiveCharacterTextSplitter`: Splits documents into smaller chunks for better retrieval.  \n",
    "\n",
    "- **Vector Database for Efficient Search**  \n",
    "  - `FAISS`: A fast vector search library for storing and retrieving document embeddings.  \n",
    "  - `HuggingFaceEmbeddings`: Generates embeddings using a **pre-trained transformer model** for similarity search.  \n",
    "\n",
    "- **LLM (Language Model Processing)**  \n",
    "  - Used to generate responses strictly based on retrieved document content.  \n",
    "\n",
    "This setup ensures an efficient **retrieval-augmented workflow** where documents are processed, stored, and queried seamlessly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from crewai import LLM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. PDF Processing and Vector Store Creation**  \n",
    "\n",
    "This function processes a PDF document, splits it into smaller chunks, and creates a vector store for efficient similarity-based search.  \n",
    "\n",
    "### **Steps:**\n",
    "1. **Load the PDF**:  \n",
    "   - The PDF document is loaded from the specified file path using a PDF loader.\n",
    "\n",
    "2. **Split the Document**:  \n",
    "   - The document is split into smaller, manageable chunks using a text splitter. The chunk size is defined to ensure context is preserved across chunks with some overlap.\n",
    "\n",
    "3. **Generate Embeddings**:  \n",
    "   - Each document chunk is converted into numerical representations (embeddings) using a pre-trained HuggingFace model. These embeddings capture the semantic meaning of the content.\n",
    "\n",
    "4. **Create FAISS Vector Store**:  \n",
    "   - The generated embeddings are stored in a FAISS vector store, which enables fast similarity search for document retrieval.\n",
    "\n",
    "5. **Return the Vector Store**:  \n",
    "   - The vector store is returned, ready for use in the query process to retrieve relevant document chunks based on similarity.\n",
    "\n",
    "This process enables efficient document retrieval by transforming PDF content into embeddings, making it ready for similarity search and query handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=220)\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Load and Process the PDF**\n",
    "\n",
    "In this section, we load and process the PDF document to create a vector store for document retrieval.  \n",
    "\n",
    "### **Steps:**\n",
    "1. **Load and Process the PDF**:  \n",
    "   - The PDF document is processed by calling the `process_pdf` function, which loads the document, splits it into chunks, generates embeddings, and stores them in a FAISS vector store.\n",
    "\n",
    "2. **Create the Retriever**:  \n",
    "   - The vector store is converted into a retriever with the specified number of top document results (`k=5`). The retriever will fetch the most relevant document chunks based on similarity to a given query.\n",
    "\n",
    "This step prepares the system for efficient document retrieval by transforming the PDF into a searchable vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "/var/folders/l3/524d7s611rs3hl7hsd6rk25w0000gn/T/ipykernel_27617/1465419141.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and process the PDF\n",
    "pdf_path = \"Revolutionizing YouTube Video Summaries.pdf\"\n",
    "vectorstore = process_pdf(pdf_path)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Query Refinement Agent\n",
    "\n",
    "The **Query Refinement Agent** is designed to enhance user queries by improving clarity, specificity, and context. This ensures that document retrieval is more accurate, leading to better results in the downstream retrieval and response generation processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryRefinementAgent(Agent):\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\n",
    "            role=\"Query Refiner\",\n",
    "            backstory=\"I enhance user queries by clarifying intent and adding relevant context to improve search accuracy.\",\n",
    "            goal=\"Refine the user's query to retrieve the most relevant document excerpts.\"\n",
    "        )\n",
    "        self.llm = llm\n",
    "\n",
    "    def execute_task(self, task: Task, context: dict = None, tools: list = None):\n",
    "        query = task.description\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are an AI assistant that refines user queries for document retrieval. \"\n",
    "            \"Rephrase the query to make it clearer and more specific without altering its intent.\\n\\n\"\n",
    "            f\"Original Query: {query}\\n\\n\"\n",
    "            \"Refined Query:\"\n",
    "        )\n",
    "\n",
    "        refined_query = self.llm.call([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ])\n",
    "\n",
    "        return refined_query.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2  Retrieval Agent**\n",
    "\n",
    "In this section, we define and initialize the **PDFRetrievalAgent**, which is responsible for retrieving relevant excerpts from the PDF based on a user query.\n",
    "\n",
    "### **Steps:**\n",
    "1. **Define the Retrieval Agent Class**:  \n",
    "   - The `PDFRetrievalAgent` class inherits from the `Agent` class and is configured with a specific role, backstory, and goal. The agent's purpose is to fetch the most relevant document excerpts based on a user query.\n",
    "   \n",
    "2. **Initialize the Retriever**:  \n",
    "   - The agent stores the `retriever` (created in the previous step) as a private attribute, enabling the agent to perform efficient document retrieval.\n",
    "\n",
    "3. **Execute the Retrieval Task**:  \n",
    "   - The `execute_task` method takes a user query, retrieves the top documents from the vector store, and concatenates the text of the relevant excerpts for further processing.\n",
    "\n",
    "4. **Initialize the Retrieval Agent**:  \n",
    "   - The `pdf_retrieval_agent` is initialized and ready to retrieve document excerpts based on user input.\n",
    "\n",
    "This step defines the agent responsible for the retrieval process, ensuring that relevant document excerpts are fetched based on similarity to a user’s query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the Retrieval Agent\n",
    "class PDFRetrievalAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            role=\"PDF Retriever\",\n",
    "            backstory=\"I retrieve relevant information from research papers stored as PDFs.\",\n",
    "            goal=\"Fetch the most relevant document excerpts based on a user query.\"\n",
    "        )\n",
    "        self._retriever = retriever  # Store the retriever as a private attribute\n",
    "\n",
    "    def execute_task(self, task: Task, context: dict = None, tools: list = None):\n",
    "        query = task.description\n",
    "        docs = self._retriever.invoke(query)\n",
    "        retrieved_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "        return retrieved_text\n",
    "\n",
    "# Initialize the Agent\n",
    "pdf_retrieval_agent = PDFRetrievalAgent()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. LLM Agent**\n",
    "\n",
    "In this section, we define and initialize the **LLMAgent**, which processes the retrieved document excerpts and generates meaningful insights based on them.\n",
    "\n",
    "### **Steps:**\n",
    "1. **Define the LLM Agent Class**:  \n",
    "   - The `LLMAgent` class inherits from the `Agent` class and is configured with a specific role, backstory, and goal. The agent's purpose is to analyze and summarize the document excerpts retrieved by the **PDFRetrievalAgent** and generate a clear response.\n",
    "\n",
    "2. **Initialize the LLM Model**:  \n",
    "   - The agent is initialized with an LLM model, which will be used to process the retrieved text and generate answers.\n",
    "\n",
    "3. **Execute the Task**:  \n",
    "   - The `execute_task` method takes the retrieved text (context) and the user query (task description). It first ensures that the context is valid. If no valid context is provided, the agent returns a default response: \"No relevant information found in the document.\"\n",
    "   - The **system prompt** is constructed to instruct the LLM to answer strictly based on the provided document excerpts, avoiding any external knowledge.\n",
    "   - The agent then invokes the LLM model to generate a response based on the provided query and context.\n",
    "\n",
    "4. **Generate the Response**:  \n",
    "   - The LLM processes the system prompt and the user query, generating a response grounded only in the retrieved document content.\n",
    "\n",
    "This step defines the agent responsible for summarizing and interpreting the retrieved text, ensuring that the responses are strictly based on the document content and not external information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgent(Agent):\n",
    "    def __init__(self, llm):\n",
    "        super().__init__(\n",
    "            role=\"LLM Processor\",\n",
    "            backstory=\"I analyze and refine retrieved excerpts to generate meaningful insights.\",\n",
    "            goal=\"Summarize and interpret retrieved text to provide a clear response.\"\n",
    "        )\n",
    "        self.llm = llm\n",
    "    \n",
    "    def execute_task(self, task: Task, context: dict = None, tools: list = None):\n",
    "        if not context or not isinstance(context, str) or len(context.strip()) == 0:\n",
    "            return \"No relevant information found in the document.\"\n",
    "        \n",
    "        system_prompt = (\n",
    "            \"You are an AI assistant that answers ONLY based on the provided document excerpts. \"\n",
    "            \"Do not use external knowledge. If the answer is not found, reply with 'Not found in the document.'\\n\\n\"\n",
    "            \"DOCUMENT EXCERPTS:\\n\" + context\n",
    "        )\n",
    "\n",
    "        return self.llm.call([{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": task.description}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Initialize the Agents**\n",
    "\n",
    "In this section, we initialize the **LLM model** and create the associated **LLMAgent** responsible for processing the retrieved text and generating meaningful responses.\n",
    "\n",
    "### **Steps:**\n",
    "1. **Initialize the LLM Model**:  \n",
    "   - We initialize the LLM model by specifying the model identifier (`ollama/deepseek-r1:1.5b`) and the base URL (`http://localhost:11434`) where the model is hosted. This model will be used by the **LLMAgent** to generate responses.\n",
    "\n",
    "2. **Create the LLMAgent**:  \n",
    "   - The `LLMAgent` is initialized with the LLM model, which enables it to process the retrieved document excerpts.\n",
    "\n",
    "3. **Define the LLM Task**:  \n",
    "   - A `Task` is created for the **LLMAgent** with the following attributes:  \n",
    "     - **Description**: \"Analyze and summarize the retrieved text.\"  \n",
    "     - **Expected Output**: \"A well-structured response based on the retrieved excerpts.\"  \n",
    "     - **Agent**: The agent responsible for this task is the `LLMAgent` initialized earlier.\n",
    "\n",
    "This step sets up the agent that will analyze and summarize the retrieved document content, preparing it for the next steps in the system’s execution pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Example Usage**\n",
    "\n",
    "In this section, we demonstrate how the agents work together to handle a user query. The process involves querying the **PDFRetrievalAgent** for relevant document excerpts and then passing the results to the **LLMAgent** for summarization.\n",
    "\n",
    "### **Steps:**\n",
    "1. **Define the Query**:  \n",
    "   - A user query, such as \"What are the prerequisites to run the project?\", is defined to be processed by the system.\n",
    "\n",
    "2. **Create the Retrieval Task**:  \n",
    "   - A task is created for the **PDFRetrievalAgent** with the query as its description. The expected output is \"Relevant excerpts from the PDF.\"\n",
    "\n",
    "3. **Define the Crew**:  \n",
    "   - A **Crew** is initialized to manage the execution of the agents and tasks.  \n",
    "     - **Agents**: Both the **PDFRetrievalAgent** and the **LLMAgent** are included in the crew.  \n",
    "     - **Tasks**: The task for **PDFRetrievalAgent** and the summarization task for **LLMAgent** are included.  \n",
    "     - **Context Flow**: Defines the flow of context between tasks. Here, the results of the **retrieval_task** will be passed to the **llm_task** for further processing.\n",
    "\n",
    "4. **Execute the Crew**:  \n",
    "   - The `crew.kickoff()` function initiates the tasks, and the agents execute their respective roles sequentially.  \n",
    "   - The result of the execution is printed, showing the raw output.\n",
    "\n",
    "This part demonstrates how the agents and tasks are orchestrated to handle the user query, retrieve relevant information, and generate a meaningful response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm looking at the user's query. They provided a document excerpt about the Nested Retrieval-Augmented Generation (RAG) system created by napkin.ai. The task is to analyze and summarize that text.\n",
      "\n",
      "First, I need to understand what RAG entails. From the user's message, it seems like RAG combines retrieval from external sources with augmented learning using AI. It uses a system called the YoutubeLoader method which probably extracts video transcripts from YouTube URLs. Then it splits this transcript into manageable chunks using RecursiveCharacterTextSplitter, which divides text into segments of 512 characters each. These chunks are then embedded using HuggingFaceEmbeddings and stored in a FAISS vector database.\n",
      "\n",
      "The RAG system offers functionalities like summarization and interactive Q&A powered by LangChain, Llama 3.2, and Gradio. It's designed to make the video retrieval process more efficient, especially for various users who might be students, content creators, or professionals needing quick answers.\n",
      "\n",
      "Now, considering how to structure this summary in a clear and concise manner, I should highlight the key components: the purpose of RAG, the method used (YoutubeLoader), text splitting with RecursiveCharacterTextSplitter, embedding techniques, and the additional functionalities it provides like summarization and Q&A. It's important to mention that this system enhances the efficiency of video retrieval by integrating external data processing with AI for better understanding and analysis.\n",
      "\n",
      "I should make sure not to include any personal opinions or outside knowledge since the response is based solely on the provided document excerpt. The summary should be informative yet straightforward, capturing all essential points without unnecessary details.\n",
      "</think>\n",
      "\n",
      "The document describes the Nested Retrieval-Augmented Generation (RAG) system created by napkin.ai. This system enhances video retrieval by integrating external data processing with AI for better understanding and analysis. It uses a method called YoutubeLoader.from_youtube_url, which extracts video transcripts from YouTube URLs. The transcript is then split into manageable chunks using the RecursiveCharacterTextSplitter, dividing text into segments of 512 characters each. These chunks are embedded using HuggingFaceEmbeddings, transformed into numerical representations suitable for machine learning tasks. The embeddings are stored in a FAISS vector database. The RAG system offers functionalities such as summarization and interactive Q&A powered by LangChain, Llama 3.2, and Gradio. It enables efficient retrieval of lengthy or detailed video content by transforming it into concise summaries and facilitating quick analysis.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=\"ollama/deepseek-r1:1.5b\", base_url=\"http://localhost:11434\")\n",
    "# Example usage\n",
    "query = \"what are the Prerequisites to Run the Project\"\n",
    "query_refinement_agent = QueryRefinementAgent(llm)\n",
    "query_refinement_task = Task(\n",
    "    description=query,\n",
    "    expected_output=\"A well-structured and precise query for document retrieval.\",\n",
    "    agent=query_refinement_agent\n",
    ")\n",
    "\n",
    "retrieval_task = Task(\n",
    "    description=\"Retrieve the most relevant excerpts from the uploaded PDF based on the refined query.\",\n",
    "    expected_output=\"A list of the most relevant document excerpts.\",\n",
    "    agent=pdf_retrieval_agent\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_agent = LLMAgent(llm)\n",
    "llm_task = Task(\n",
    "    description=\"Analyze and summarize the retrieved text.\",\n",
    "    expected_output=\"A well-structured response based on the retrieved excerpts.\",\n",
    "    agent=llm_agent\n",
    ")\n",
    "\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[query_refinement_agent, pdf_retrieval_agent, llm_agent],\n",
    "    tasks=[query_refinement_task, retrieval_task,llm_task],\n",
    "    verbose=True,\n",
    "    process=Process.sequential,\n",
    "    context_flow={\"retrieval_task\": \"query_refinement_task\",\"llm_task\":\"retrieval_task\"} \n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(result.raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Extract and Remove `<think>` Content**\n",
    "\n",
    "In this section, we process the raw result output by extracting and removing specific content enclosed within `<think>` tags. This ensures that only the relevant parts of the response are shown to the user.\n",
    "\n",
    "### **Steps:**\n",
    "1. **Extract Content Inside `<think>` Tags**:  \n",
    "   - The `extract_think_content` function uses regular expressions to find and extract content within `<think>` and `</think>` tags. If content is found, it is returned; otherwise, an empty string is returned.\n",
    "\n",
    "2. **Remove Content Inside `<think>` Tags**:  \n",
    "   - The `remove_think_content` function uses regular expressions to remove everything between `<think>` and `</think>` tags. This is useful to clean up the result and ensure only the relevant content remains.\n",
    "\n",
    "3. **Process the Raw Result**:  \n",
    "   - The `think_content` variable stores any extracted content from the `<think>` tags, while the `response` variable stores the cleaned response with the `<think>` content removed.\n",
    "\n",
    "4. **Print the Final Response**:  \n",
    "   - The cleaned response (without `<think>` content) is printed, ensuring the final answer is concise and relevant.\n",
    "\n",
    "This step processes the raw response to clean and refine the output, making it ready for presentation to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_think_content(text):\n",
    "    match = re.search(r'<think>(.*?)</think>', text, flags=re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "# Function to remove everything between <think> and </think> tags\n",
    "def remove_think_content(text):\n",
    "    return re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_content=extract_think_content(result.raw)\n",
    "response=remove_think_content(result.raw)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "This notebook demonstrates the creation and orchestration of agents to process a PDF document and generate meaningful insights from user queries. The system performs the following key steps:\n",
    "\n",
    "1. **PDF Processing**: The PDF document is loaded, split into manageable chunks, and stored in a FAISS vector store for efficient retrieval using embeddings.\n",
    "2. **Retrieval Agent**: A **PDFRetrievalAgent** retrieves the most relevant document excerpts based on the user’s query.\n",
    "3. **LLM Processing**: The **LLMAgent** processes the retrieved text using a pre-trained language model, generating a well-structured response.\n",
    "4. **Task Execution**: The **Crew** orchestrates the execution of these agents, ensuring sequential processing of the tasks (retrieving and summarizing the document content).\n",
    "5. **Result Refining**: The raw response is refined by extracting or removing content enclosed in `<think>` tags, providing a clean and relevant response to the user.\n",
    "\n",
    "This system efficiently combines retrieval-based and generation-based techniques to answer user queries, making it a robust tool for document analysis and summarization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
